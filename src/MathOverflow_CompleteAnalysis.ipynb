{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488db460",
   "metadata": {},
   "source": [
    "# 1. Exploratory Network Analysis (ENA)\n",
    "\n",
    "In this notebook, we perform an exploratory analysis of the raw **MathOverflow answer-to-question** dataset (`sx-mathoverflow-a2q`) from the SNAP database.  \n",
    "This step precedes any filtering and aims to:\n",
    "\n",
    "- understand the global structure of the unfiltered interaction graph  \n",
    "- compute fundamental network statistics  \n",
    "- inspect temporal activity patterns  \n",
    "- justify later decisions on subset construction  \n",
    "- compare raw properties to known results from the literature  \n",
    "\n",
    "This analysis provides the baseline from which all subsequent processing and structural evaluation will follow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0213d",
   "metadata": {},
   "source": [
    "## 1.1 Dataset Overview\n",
    "\n",
    "We work with the `sx-mathoverflow-a2q` dataset, which contains **answers to questions**:  \n",
    "each row represents a timestamped interaction `(u, v, t)`, meaning:\n",
    "\n",
    "- user **u** answered  \n",
    "- a question originally posted by **v**  \n",
    "- at time **t** (UNIX timestamp)\n",
    "\n",
    "This dataset is a curated subset of the full MathOverflow interaction log, isolating the most meaningful \"knowledge-transfer\" edges.\n",
    "\n",
    "According to the SNAP documentation, the dataset includes:\n",
    "\n",
    "- **21,688 nodes** (unique users)  \n",
    "- **107,581 temporal answer events**  \n",
    "- **90,489 static directed edges** (after collapsing duplicates)\n",
    "\n",
    "In this section, we load the raw dataset and compute initial descriptive statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06f4d0",
   "metadata": {},
   "source": [
    "## 1.2 Loading the Dataset\n",
    "\n",
    "We begin by loading the raw `sx-mathoverflow-a2q` dataset from the `data/` directory.\n",
    "\n",
    "The file contains three columns separated by spaces: `source`, `target`, and `timestamp`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/sx-mathoverflow.txt\", delim_whitespace=True, header=None, names=[\"source\", \"target\", \"timestamp\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee61a0",
   "metadata": {},
   "source": [
    "> A pandas DataFrame makes manipulation easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2882d",
   "metadata": {},
   "source": [
    "## 1.3 Basic Data Checks\n",
    "\n",
    "Once loaded, we inspect:\n",
    "\n",
    "- the shape of the dataset   \n",
    "- count of unique users  \n",
    "- total number of interactions\n",
    "\n",
    "This allows us to confirm that the dataset matches the expected SNAP statistics and ensures data integrity before constructing the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95af437",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(pd.unique(df[['source','target']].values.ravel()))\n",
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = len(df)\n",
    "n_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07bae2",
   "metadata": {},
   "source": [
    "## 1.4 Temporal Structure of the Interactions\n",
    "\n",
    "Since each interaction includes a UNIX timestamp, we can extract temporal patterns.\n",
    "\n",
    "In this section, we:\n",
    "- convert timestamps into human-readable datetime objects  \n",
    "- extract year and month  \n",
    "- compute interaction volume per year  \n",
    "- visualize how MathOverflow activity evolves over time  \n",
    "\n",
    "This will later help justify the selection of the **2010–2012** window for the network subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "\n",
    "df = df.set_index(\"datetime\")\n",
    "interactions_by_month = df.resample('ME').size()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "interactions_by_month.plot()\n",
    "plt.title(\"Interações por mês\")\n",
    "plt.ylabel(\"Quantidade de interações\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd0c8e-73f5-402d-acb6-921618c0bcaa",
   "metadata": {},
   "source": [
    "## 1.5 Creating the graph via networkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7dcfcf-98f5-42fa-83e4-2b73ce23977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df.reset_index(), source=\"source\", target=\"target\", create_using=nx.DiGraph)\n",
    "\n",
    "print(f\"\\nGrafo carregado com {G.number_of_nodes()} nós e {G.number_of_edges()} arestas\")\n",
    "\n",
    "largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "print(f\"\\nTamanho da maior componente fraca: {len(largest_cc)} nós ({len(largest_cc)/G.number_of_nodes():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7be84-a631-4218-9d87-e840595855a4",
   "metadata": {},
   "source": [
    "## 2 Creating the Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036af9f9-d3eb-4953-a27d-739398b53093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 1. Subset temporal\n",
    "# ============================================================\n",
    "\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2012-12-31\"\n",
    "\n",
    "subset_by_time = df.loc[\n",
    "    (df.index >= start_date) & (df.index <= end_date)\n",
    "]\n",
    "\n",
    "all_nodes = pd.concat([subset_by_time[\"source\"], subset_by_time[\"target\"]])\n",
    "unique_users = all_nodes.nunique()\n",
    "print(f\"\\nNúmero total de usuários após isolar o dataset temporalmente: {unique_users}\")\n",
    "print(f\"\\nTotal de interações pós isolar o dataset temporalmente (de {start_date} a {end_date}) : {len(subset_by_time)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Contagem de interações por utilizador (src + dst)\n",
    "# ============================================================\n",
    "\n",
    "interaction_counts = (\n",
    "    subset_by_time['source'].value_counts() +\n",
    "    subset_by_time['target'].value_counts()\n",
    ").fillna(0)\n",
    "\n",
    "# Selecionar utilizadores com mais de 50 interações\n",
    "active_users = interaction_counts[interaction_counts > 25].index\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Filtrar dataset para manter apenas interações entre esses utilizadores\n",
    "# ============================================================\n",
    "\n",
    "subset_active = subset_by_time[\n",
    "    subset_by_time['source'].isin(active_users) &\n",
    "    subset_by_time['target'].isin(active_users)\n",
    "]\n",
    "\n",
    "print(f\"\\nInterações restantes após filtro por utilizadores ativos: {len(subset_active)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Criar grafo com utilizadores ativos\n",
    "# ============================================================\n",
    "\n",
    "G_active = nx.from_pandas_edgelist(\n",
    "    subset_active.reset_index(), 'source', 'target', create_using=nx.DiGraph\n",
    ")\n",
    "\n",
    "print(f\"\\nGrafo final contém:\")\n",
    "print(f\"- {G_active.number_of_nodes()} nós\")\n",
    "print(f\"- {G_active.number_of_edges()} arestas (estáticas)\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Maior componente conectada\n",
    "# ============================================================\n",
    "\n",
    "largest_cc = max(nx.weakly_connected_components(G_active), key=len)\n",
    "print(f\"\\nTamanho da maior componente fraca: {len(largest_cc)} nós \"\n",
    "      f\"({len(largest_cc)/G_active.number_of_nodes():.2%})\")\n",
    "\n",
    "cc_active_subgraph = G_active.subgraph(largest_cc)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Exportar para GraphML para o Gephi\n",
    "# ============================================================\n",
    "\n",
    "nx.write_graphml(cc_active_subgraph, \"mathoverflow_active_users_25.graphml\")\n",
    "print(\"\\nSubset exportado como 'mathoverflow_active_users_25.graphml'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98dbce3-0570-4e44-83a6-9450e658e268",
   "metadata": {},
   "source": [
    "## 3 Analyzing the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6951afe-c0d8-4eb6-ad73-c790642b0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n===============================================================\")\n",
    "print(\"1. PROPRIEDADES DE CONECTIVIDADE E SMALL-WORLDNESS\")\n",
    "print(\"===============================================================\")\n",
    "\n",
    "N = cc_active_subgraph.number_of_nodes()\n",
    "E = cc_active_subgraph.number_of_edges()\n",
    "\n",
    "# 1.1 Coeficiente de Agrupamento Global (Clustering Coefficient)\n",
    "T = nx.transitivity(cc_active_subgraph)\n",
    "print(f\"Clustering Coefficient): {T:.4f}\")\n",
    "\n",
    "\n",
    "p = nx.density(cc_active_subgraph)\n",
    "print(f\"Density: {p:.4f}\")\n",
    "\n",
    "# 1.2 Comprimento Médio do Caminho (Average Path Length - APL)\n",
    "try:\n",
    "    APL = nx.average_shortest_path_length(cc_active_subgraph)\n",
    "    print(f\"Comprimento Médio do Caminho (APL): {APL:.2f}\")\n",
    "except nx.NetworkXError:\n",
    "    print(\"APL: Não foi possível calcular o Average Path Length.\")\n",
    "    APL = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4adae0-0f23-4b70-901d-7bd29af4c046",
   "metadata": {},
   "source": [
    "The high transitivity indicates the formation of communities since it proves that users like to interact around the same topics/people. The density indicates that the network is sparse. The lack of a average_shortest_path_length happens because although the graph is fully connected (LWC) it´s also directed, which means that A might be connected to B, and able to transmit information but B isn´t able to the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5d7a5-5c3c-44c3-a2f7-2fcf062dc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_undirected = cc_active_subgraph.to_undirected(as_view=True)\n",
    "\n",
    "# 1.2 Comprimento Médio do Caminho (Average Path Length - APL)\n",
    "try:\n",
    "    APL = nx.average_shortest_path_length(G_undirected)\n",
    "    print(f\"Comprimento Médio do Caminho (APL): {APL:.2f}\")\n",
    "except nx.NetworkXError:\n",
    "    print(\"APL: Não foi possível calcular o Average Path Length.\")\n",
    "    APL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e368c-6b8c-47d5-80f1-ce61c0ef3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Análise de Grau e Distribuições\n",
    "# ============================================================\n",
    "print(\"\\n===============================================================\")\n",
    "print(\"2. ANÁLISE DE GRAU\")\n",
    "print(\"===============================================================\")\n",
    "\n",
    "# Calcular o grau de entrada (respostas recebidas) e saída (respostas dadas)\n",
    "in_degrees = [d for n, d in cc_active_subgraph.in_degree()]\n",
    "out_degrees = [d for n, d in cc_active_subgraph.out_degree()]\n",
    "\n",
    "avg_in_degree = np.mean(in_degrees)\n",
    "avg_out_degree = np.mean(out_degrees)\n",
    "\n",
    "print(f\"Grau Médio de Entrada (k_in): {avg_in_degree:.2f}\")\n",
    "print(f\"Grau Médio de Saída (k_out): {avg_out_degree:.2f}\")\n",
    "print(f\"Grau Máximo de Entrada (max k_in): {np.max(in_degrees)}\")\n",
    "print(f\"Grau Máximo de Saída (max k_out): {np.max(out_degrees)}\")\n",
    "\n",
    "# Plota a Distribuição de Grau\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Distribuição de Grau de ENTRADA (k_in)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(in_degrees, bins=50, log=True, color='skyblue', edgecolor='black')\n",
    "plt.title('In-Degree Distribuition (log scale)')\n",
    "plt.xlabel('In-Degree (k_in)')\n",
    "plt.ylabel('Frequency (log)')\n",
    "\n",
    "# Distribuição de Grau de SAÍDA (k_out)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(out_degrees, bins=50, log=True, color='lightcoral', edgecolor='black')\n",
    "plt.title('Out-Degree Distribuition (log scale)')\n",
    "plt.xlabel('Out-Degree (k_out)')\n",
    "plt.ylabel('Frequency (log)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretação:\n",
    "# Se o gráfico em log-log (o que é uma representação comum para esta análise) mostrar uma linha reta,\n",
    "# isso é um forte indício de uma rede Sem Escala (Scale-Free), regida por uma Lei de Potência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dcc1d-135a-4263-89c8-89f64aa8aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community.community_louvain as community_louvain\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assumindo que 'cc_active_subgraph' é o seu grafo dirigido (DiGraph)\n",
    "# O algoritmo Louvain funciona melhor em grafos não dirigidos.\n",
    "# Portanto, trabalhamos com a versão não dirigida do seu subgrafo.\n",
    "G_undirected = cc_active_subgraph.to_undirected(as_view=True)\n",
    "\n",
    "# 1. Aplicar o Algoritmo Louvain\n",
    "# O resultado é um dicionário onde a chave é o nó (usuário) e o valor é o ID da comunidade (0, 1, 2, ...)\n",
    "partition = community_louvain.best_partition(G_undirected)\n",
    "\n",
    "# 2. Calcular a Modularidade (Métrica de qualidade do agrupamento)\n",
    "modularity = community_louvain.modularity(partition, G_undirected)\n",
    "\n",
    "# 3. Análise da Estrutura\n",
    "num_communities = max(partition.values()) + 1\n",
    "community_sizes = pd.Series(partition.values()).value_counts().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n==============================================================\")\n",
    "print(\"1. RESULTADOS DA DETEÇÃO DE COMUNIDADES (LOUVAIN)\")\n",
    "print(\"==============================================================\")\n",
    "print(f\"Modularidade Global (Q): {modularity:.4f}\")\n",
    "print(f\"Número Total de Comunidades: {num_communities}\")\n",
    "print(f\"Tamanho da Maior Comunidade: {community_sizes.iloc[0]} nós\")\n",
    "print(f\"Tamanho da Segunda Maior Comunidade: {community_sizes.iloc[1]} nós\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca897e-0a6a-40cb-9bc9-e6b729a18281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
